{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Social Influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is based on data from the [Influencers in Social Networks](https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network) competition hosted on Kaggle. \n",
    "\n",
    "The dataset comprises a standard, pair-wise preference learning task. Each datapoint describes two individuals using features based on twitter activity (such as volume of interactions, number of followers, etc). The discrete label represents a human judgement about which one of the two individuals is more influential (1 means A > B, 0 means B > A).\n",
    "\n",
    "The goal of the challenge is to train a machine learning model which, for a pair of individuals, predicts the human judgement on who is more influential with high accuracy. Then, using this model we will quantify the value of influence and explore how a business can identify and leverage influencers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log function\n",
    "def transform_features(x):\n",
    "    return np.log(1+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train and test 70/30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.ix[:,1:], data.ix[:,0], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log transform features\n",
    "X_train = transform_features(X_train)\n",
    "X_test = transform_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize scaler with train\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale train and test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate userA and userB data\n",
    "X_train_A = X_train_scaled[:,:11]\n",
    "X_train_B = X_train_scaled[:,11:]\n",
    "X_test_A = X_test_scaled[:,:11]\n",
    "X_test_B = X_test_scaled[:,11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate differences userA - userB for each feature\n",
    "X_train_new = X_train_A - X_train_B\n",
    "X_test_new = X_test_A - X_test_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for multicollinearity\n",
    "#DataFrame(X_train_new).corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {'logreg': linear_model.LogisticRegression(C=1.0),\n",
    "          'boost': GradientBoostingClassifier(n_estimators=100, learning_rate=0.04, random_state=1),\n",
    "          'rf': RandomForestClassifier(n_estimators=10),\n",
    "          'knn': KNeighborsClassifier(n_neighbors=5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty datframe for results\n",
    "results_df = DataFrame(columns=['Model', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through models and append accuracy scores to results_df\n",
    "for k, v in models.iteritems():\n",
    "    clf = v\n",
    "    clf.fit(X_train_new, y_train)\n",
    "    pred = clf.predict(X_test_new)\n",
    "    results_df = results_df.append({'Model': k, 'Accuracy': accuracy_score(pred, y_test)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.734545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.727879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boost</td>\n",
       "      <td>0.755758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.755758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy\n",
       "0     knn  0.734545\n",
       "1      rf  0.727879\n",
       "2   boost  0.755758\n",
       "3  logreg  0.755758"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy scores for the 4 models are relatively close. Boosting and logistic regression tie for first with accuracy scores of ~75.58%. A pairwise correlation table of the predictor variables showed multicollinearity between several variables, so we will move forward with the boosting model as it has built-in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix function\n",
    "def accuracy(pred, actual):\n",
    "    print 'Accuracy: %s' %(np.mean(pred == actual))\n",
    "    print(pd.crosstab(actual, pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run boosting again for confusion matrix\n",
    "boost = GradientBoostingClassifier(n_estimators=100, learning_rate=0.04, random_state=1)\n",
    "boost.fit(X_train_new, y_train)\n",
    "boost_pred = clf.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755757575758\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          616  219   835\n",
      "1          184  631   815\n",
      "All        800  850  1650\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "accuracy(boost_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get new feature names\n",
    "col_list = []\n",
    "for i in list(data.ix[:,1:12].columns.values):\n",
    "    col_list.append(\"A-B_\"+i[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create feature importance dataframe\n",
    "features_df = DataFrame(boost.feature_importances_, index=col_list)\n",
    "features_df.columns = ['Importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-B_listed_count</th>\n",
       "      <td>0.252978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_follower_count</th>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_network_feature_1</th>\n",
       "      <td>0.178901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_network_feature_2</th>\n",
       "      <td>0.093876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_following_count</th>\n",
       "      <td>0.085572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_retweets_received</th>\n",
       "      <td>0.077644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_retweets_sent</th>\n",
       "      <td>0.043102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_posts</th>\n",
       "      <td>0.036991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_mentions_received</th>\n",
       "      <td>0.023371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_network_feature_3</th>\n",
       "      <td>0.013852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-B_mentions_sent</th>\n",
       "      <td>0.012012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Importance\n",
       "A-B_listed_count         0.252978\n",
       "A-B_follower_count       0.181700\n",
       "A-B_network_feature_1    0.178901\n",
       "A-B_network_feature_2    0.093876\n",
       "A-B_following_count      0.085572\n",
       "A-B_retweets_received    0.077644\n",
       "A-B_retweets_sent        0.043102\n",
       "A-B_posts                0.036991\n",
       "A-B_mentions_received    0.023371\n",
       "A-B_network_feature_3    0.013852\n",
       "A-B_mentions_sent        0.012012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort dataframe descending by importance\n",
    "features_df.sort(['Importance'], ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have feature importance from the boosting model. Diff in listed_count is the most important predictor of social influence followed by diff in follower_count, diff in network_feature_1, and diff in network_feature_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get followers counts for financial value analysis\n",
    "fv_df = data.ix[y_test.index,[1,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add actual and predicted values\n",
    "fv_df['Actual'] = y_test\n",
    "fv_df['Predicted'] = boost_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export to csv for analysis\n",
    "fv_df.to_csv('financial_value.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the financial value of the model, which would be the lift in profits from using analytics versus not.\n",
    "\n",
    "####Assume a retailer wants influencers to tweet its promotion for a product:\n",
    "* Without analytics, retailer offers \\$1 to each person to tweet once\n",
    "* With analytics, retailer offers \\$2 to those identified as influencers to send two tweets each\n",
    "* Non-influencer tweets are no benefit to a retailer\n",
    "* Influencer tweet leads to a 0.10% chance that a follower will buy one unit of a product\n",
    "* Influencer tweets leads to a 0.15% chance that a follower will buy one unit of a product\n",
    "* Retailer profit margin \\$50 per unit, one customer can buy only one unit\n",
    "\n",
    "Calculations done in [financial_value.xlsx](https://github.com/juliaawu/mis184n-social-media-analytics/blob/master/predicting-social-influence/financial_value.xlsx)\n",
    "\n",
    "Given the above assumptions, the promotion effort would have generated \\$82k in profit with no model, \\$113k with the boosting model, and \\$123k with a perfect model. Using analytics to predict social influence would generate a 38% lift in sales, equating to \\$31k in additional profit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
